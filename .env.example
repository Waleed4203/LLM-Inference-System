# Redis Configuration
REDIS_HOST=localhost
REDIS_PORT=6379
REDIS_DB=0

# API Configuration
API_KEYS=your-secret-key-here,another-key-here
FASTAPI_HOST=0.0.0.0
FASTAPI_PORT=8000

# Model Configuration
# Backend: "transformers" or "ollama"
MODEL_BACKEND=ollama
MODEL_NAME=TheBloke/Llama-2-7B-Chat-GPTQ
MODEL_DEVICE=cuda
USE_QUANTIZATION=true
MAX_NEW_TOKENS=512
TEMPERATURE=0.7

# Ollama Configuration (used when MODEL_BACKEND=ollama)
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=llama2

# Task Configuration
TASK_TIME_LIMIT=120
CELERY_CONCURRENCY=1

# Logging
LOG_LEVEL=INFO
LOG_DIR=logs
